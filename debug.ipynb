{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameterts in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the number of parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    \"\"\"A dictionary with dot notation access to attributes.\"\"\"\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "    def __delattr__(self, key):\n",
    "        try:\n",
    "            del self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
    "        \n",
    "# Function to convert existing dictionary to DotDict\n",
    "def dict_to_dotdict(d):\n",
    "    if not isinstance(d, dict):\n",
    "        return d\n",
    "    return DotDict({k: dict_to_dotdict(v) if isinstance(v, dict) else v for k, v in d.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 7486402\n",
      "Trainable parameters: 7486402\n"
     ]
    }
   ],
   "source": [
    "from models.transformer_bilstm_v2 import TransformerBiLSTM\n",
    "from models.transformer_v1 import Transformer\n",
    "opt = {\n",
    "    'block_size': 15552,\n",
    "    'block_stride': 972,\n",
    "    'patch_size': 18,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'fog_model_input_dim': 54,\n",
    "    'fog_model_dim': 320,\n",
    "    'fog_model_num_heads': 8,\n",
    "    'fog_model_num_encoder_layers': 5,\n",
    "    'fog_model_num_lstm_layers': 2,\n",
    "    'fog_model_first_dropout': 0.1,\n",
    "    'fog_model_encoder_dropout': 0.1,\n",
    "    'fog_model_mha_dropout': 0.0,\n",
    "}\n",
    "\n",
    "opt = DotDict(opt)\n",
    "\n",
    "model = TransformerBiLSTM(opt)\n",
    "transformer_model = Transformer(opt)\n",
    "\n",
    "# Get the total and trainable parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "print(f\"TransformerBiLSTM Total parameters: {total_params}\")\n",
    "print(f\"TransformerBiLSTM Trainable parameters: {trainable_params}\")\n",
    "\n",
    "total_params, trainable_params = count_parameters(transformer_model)\n",
    "\n",
    "print(f\"Transformer Total parameters: {total_params}\")\n",
    "print(f\"Transformer Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "dict_keys(['series_name', 'start_t_idx', 'end_t_idx', 'model_input', 'gt'])\n",
      "rectified_16_dataset_fog_release\n",
      "torch.Size([15552])\n",
      "tensor([2, 2, 2], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "import joblib, random, torch\n",
    "\n",
    "random.seed(11)\n",
    "pickle_path = \"data/rectified_data/dataset_fog_release/val_dataset_fog_release.p\"\n",
    "\n",
    "all_data = joblib.load(pickle_path)\n",
    "\n",
    "print(len(all_data.keys()))\n",
    "print(all_data[200].keys())\n",
    "\n",
    "gt = all_data[200]['gt']\n",
    "print(all_data[200]['series_name'])\n",
    "print(gt.shape)\n",
    "print(gt[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]),\n",
       " tensor([[1.7707, 2.4249, 0.1701, 0.8715, 2.5939, 1.6950],\n",
       "         [1.1421, 0.6567, 0.1020, 0.8278, 0.0357, 1.0962]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "bce = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "pred = torch.rand(2,6)\n",
    "mask = torch.tensor([[0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 1]]).float()\n",
    "\n",
    "loss = bce(pred, mask)\n",
    "loss.shape, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictToObj:\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        return self.__dict__.get(name)\n",
    "    \n",
    "opt = {\n",
    "    'seed': 11,\n",
    "    'optimizer': 'adamw',\n",
    "    'learning_rate': 0.00026,\n",
    "    'adam_betas': (0.9, 0.98),\n",
    "    'adam_eps': 1.0e-09,\n",
    "    'weight_decay': 0,\n",
    "    'lr_scheduler_factor': 0.1,\n",
    "    'lr_scheduler_patience': 20,\n",
    "    'lr_scheduler_warmup_steps': 64,\n",
    "    'train_num_steps': 20000,\n",
    "    'penalty_cost': 2.0,\n",
    "    'block_size': 15552,\n",
    "    'block_stride': 972,\n",
    "    'patch_size': 18,\n",
    "    'fog_model_input_dim': 162,\n",
    "    'fog_model_dim': 320,\n",
    "    'fog_model_num_heads': 8,\n",
    "    'fog_model_num_encoder_layers': 5,\n",
    "    'fog_model_num_lstm_layers': 2,\n",
    "    'fog_model_first_dropout': 0.1,\n",
    "    'fog_model_encoder_dropout': 0.1,\n",
    "    'fog_model_mha_dropout': 0.0,\n",
    "}\n",
    "opt = DictToObj(opt)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from models.transformer_bilstm_v1 import TransformerBiLSTM\n",
    "\n",
    "random.seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "model = TransformerBiLSTM(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from data.fog_dataset_v1 import FoGDataset\n",
    "\n",
    "train_dpath = \"data/rectified_data/dataset_fog_release/train1_dataset_fog_release_blks15552_ps18.p\"\n",
    "model_path = \"runs/train/transfomer_bilstm/2024_06_12_21:12:41.10/weights/model_regular_19991.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path)['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1055,\n",
       " dict_keys(['series_name', 'start_t_idx', 'end_t_idx', 'model_input', 'gt']),\n",
       " torch.Size([864, 162]),\n",
       " torch.Size([864, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "train_ds = joblib.load(train_dpath)\n",
    "len(train_ds.keys()), train_ds[1].keys(), train_ds[1]['model_input'].shape, train_ds[1]['gt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 864, 162]), torch.Size([32, 864, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = []\n",
    "gt = []\n",
    "for i in range(32):\n",
    "    model_input.append(train_ds[i]['model_input'][None, :, :])\n",
    "    gt.append(train_ds[i]['gt'][None, :, :])\n",
    "\n",
    "model_input= torch.cat(model_input, dim=0)\n",
    "gt = torch.cat(gt, dim=0)\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 864, 162]), torch.Size([32, 864, 3]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.fog_dataset_v1 import FoGDataset\n",
    "\n",
    "val_dpath = \"data/rectified_data/dataset_fog_release/val1_dataset_fog_release_blks15552_ps18.p\"\n",
    "model_path = \"runs/train/transfomer_bilstm/2024_06_12_21:12:41.10/weights/model_regular_19991.pt\"\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(model_path)['model'])\n",
    "import joblib\n",
    "val_ds = joblib.load(val_dpath)\n",
    "\n",
    "model_input = []\n",
    "gt = []\n",
    "for i in range(32):\n",
    "    model_input.append(val_ds[i]['model_input'][None, :, :])\n",
    "    gt.append(val_ds[i]['gt'][None, :, :])\n",
    "\n",
    "model_input= torch.cat(model_input, dim=0)\n",
    "gt = torch.cat(gt, dim=0)\n",
    "\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7070),\n",
       " tensor(0.5953),\n",
       " tensor(0.6464),\n",
       " tensor(0.4415),\n",
       " tensor(4.1332, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(model_input)\n",
    "loss = loss_func(pred, gt)\n",
    "precision, recall, f1, ap = evaluation_metrics(pred, gt)\n",
    "precision, recall, f1, ap, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def norm_axis(a,b,c):\n",
    "    newa=a/(math.sqrt(float(a*a+b*b+c*c)))\n",
    "    newb=b/(math.sqrt(float(a*a+b*b+c*c)))\n",
    "    newc=c/(math.sqrt(float(a*a+b*b+c*c)))\n",
    "    return ([newa,newb,newc])\n",
    "\n",
    "def rotation_matrix(axis, theta):\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis/math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta/2.0)\n",
    "    b, c, d = -axis*math.sin(theta/2.0)\n",
    "    aa, bb, cc, dd = a*a, b*b, c*c, d*d\n",
    "    bc, ad, ac, ab, bd, cd = b*c, a*d, a*c, a*b, b*d, c*d\n",
    "    return np.array([[aa+bb-cc-dd, 2*(bc+ad), 2*(bd-ac)], \n",
    "                     [2*(bc-ad), aa+cc-bb-dd, 2*(cd+ab)], \n",
    "                     [2*(bd+ac), 2*(cd-ab), aa+dd-bb-cc]])\n",
    "\n",
    "def rotateC(image,theta,a,b,c): ## theta: angle, a, b, c, eular vector\n",
    "    axis=norm_axis(a,b,c)\n",
    "    imagenew=np.dot(image, rotation_matrix(axis,theta))\n",
    "    return imagenew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 864, 162]), torch.Size([32, 864, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.fog_dataset_v1 import FoGDataset\n",
    "\n",
    "train_dpath = \"data/rectified_data/dataset_fog_release/train1_dataset_fog_release_blks15552_ps18.p\"\n",
    "import joblib\n",
    "train_ds = joblib.load(train_dpath)\n",
    "\n",
    "model_input = []\n",
    "gt = []\n",
    "for i in range(32):\n",
    "    model_input.append(train_ds[i]['model_input'][None, :, :])\n",
    "    gt.append(train_ds[i]['gt'][None, :, :])\n",
    "\n",
    "model_input= torch.cat(model_input, dim=0)\n",
    "gt = torch.cat(gt, dim=0)\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 864, 18, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = model_input.reshape(32,864, 18, 9)\n",
    "model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 864, 18, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = model_input.reshape(32, 864, 18, 3, 3)\n",
    "model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3),\n",
       " array([[ 0.38501953, -0.68464825,  0.61888345],\n",
       "        [ 0.91940947,  0.22620226, -0.32174332],\n",
       "        [ 0.08028816,  0.69288477,  0.71656438]]),\n",
       " 215.03446095139176)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "theta = random.random()*math.pi*2\n",
    "theta = random.random()*360\n",
    "a=random.random()\n",
    "b=random.random()\n",
    "c=random.random()\n",
    "axis=norm_axis(a,b,c)\n",
    "tmp = rotation_matrix(axis,theta)\n",
    "tmp.shape, tmp, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.6030, -0.3699, -0.0446],\n",
      "          [-0.6301, -0.0343, -1.0127],\n",
      "          [-0.6837,  0.2872,  0.8251]],\n",
      "\n",
      "         [[-0.6274, -0.3699, -0.0446],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.6837,  0.0158,  0.6969]],\n",
      "\n",
      "         [[-0.6274, -0.3699, -0.0446],\n",
      "          [-0.6479,  0.0539, -0.9907],\n",
      "          [-0.7707, -0.0684,  0.6969]],\n",
      "\n",
      "         [[-0.5542, -0.3425, -0.1125],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.0684,  0.6969]],\n",
      "\n",
      "         [[-0.5542, -0.3425, -0.1125],\n",
      "          [-0.6301, -0.0343, -0.9443],\n",
      "          [-0.7137,  0.0158,  0.5687]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6301,  0.0098, -0.9907],\n",
      "          [-0.7137,  0.0158,  0.5012]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6123,  0.0098, -1.0347],\n",
      "          [-0.7437, -0.1619,  0.6294]],\n",
      "\n",
      "         [[-0.5786, -0.3972, -0.0786],\n",
      "          [-0.6301, -0.0829, -0.9907],\n",
      "          [-0.7437, -0.2555,  0.7576]],\n",
      "\n",
      "         [[-0.5786, -0.3972, -0.0786],\n",
      "          [-0.6301, -0.0343, -1.0127],\n",
      "          [-0.7437, -0.1619,  0.5687]],\n",
      "\n",
      "         [[-0.6518, -0.3425, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.0684,  0.6294]],\n",
      "\n",
      "         [[-0.6518, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.1270, -1.0127],\n",
      "          [-0.7137, -0.0684,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6123, -0.0829, -0.9663],\n",
      "          [-0.7137, -0.3397,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6123, -0.0829, -0.9663],\n",
      "          [-0.8006, -0.1619,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.4245, -0.0446],\n",
      "          [-0.6479, -0.0829, -0.9663],\n",
      "          [-0.7707, -0.2555,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.4245, -0.0446],\n",
      "          [-0.6479, -0.0343, -0.9443],\n",
      "          [-0.8006, -0.1619,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.0829, -0.9907],\n",
      "          [-0.8306, -0.0684,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.1270, -0.9443],\n",
      "          [-0.8306, -0.0684,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6301,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.1619,  0.6294]]],\n",
      "\n",
      "\n",
      "        [[[-0.5786, -0.3425, -0.1125],\n",
      "          [-0.6301, -0.0829, -0.9663],\n",
      "          [-0.7437, -0.2555,  0.5687]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.1125],\n",
      "          [-0.6479, -0.0829, -0.9907],\n",
      "          [-0.7437, -0.1619,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9663],\n",
      "          [-0.7707, -0.4333,  0.6969]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6301,  0.0098, -0.9443],\n",
      "          [-0.7437, -0.3397,  0.5687]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6301, -0.0343, -1.0127],\n",
      "          [-0.7707, -0.0684,  0.5012]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6479,  0.0098, -0.9663],\n",
      "          [-0.7707, -0.3397,  0.7576]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6479, -0.0343, -0.9663],\n",
      "          [-0.7707, -0.1619,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.4245, -0.0446],\n",
      "          [-0.6301,  0.0539, -0.9907],\n",
      "          [-0.8306,  0.0158,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.1619,  0.7576]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.8006, -0.1619,  0.5687]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.0786],\n",
      "          [-0.6123,  0.0539, -1.0347],\n",
      "          [-0.8006, -0.1619,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.1125],\n",
      "          [-0.6123, -0.1270, -0.9907],\n",
      "          [-0.7707, -0.3397,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.1125],\n",
      "          [-0.6657, -0.0829, -1.0127],\n",
      "          [-0.7707, -0.3397,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.1125],\n",
      "          [-0.6479,  0.0539, -1.0127],\n",
      "          [-0.8006, -0.3397,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.4792, -0.0106],\n",
      "          [-0.6479, -0.0343, -1.0127],\n",
      "          [-0.7707, -0.2555,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.4792, -0.0106],\n",
      "          [-0.6301,  0.0539, -0.9907],\n",
      "          [-0.7707, -0.3397,  0.6294]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.0786],\n",
      "          [-0.6479,  0.0539, -0.9907],\n",
      "          [-0.7707, -0.3397,  0.6294]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.0343, -0.9443],\n",
      "          [-0.7707, -0.1619,  0.7576]]]])\n",
      "\n",
      "[[[[-0.65867335 -0.25773804 -0.04611335]\n",
      "   [-0.47125663 -0.3060434  -1.05258558]\n",
      "   [-0.71052971  0.67903355  0.51455767]]\n",
      "\n",
      "  [[-0.68220213 -0.25380784 -0.05134019]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.75398781  0.38329243  0.48781002]]\n",
      "\n",
      "  [[-0.68220213 -0.25380784 -0.05134019]\n",
      "   [-0.47147285 -0.21430918 -1.06578071]\n",
      "   [-0.85687631  0.32027554  0.49741002]]\n",
      "\n",
      "  [[-0.59577262 -0.26582648 -0.10714944]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.85687631  0.32027554  0.49741002]]\n",
      "\n",
      "  [[-0.59577262 -0.26582648 -0.10714944]\n",
      "   [-0.4809573  -0.28064303 -0.9898185 ]\n",
      "   [-0.76468955  0.34051223  0.36375752]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.46435076 -0.25752611 -1.04719111]\n",
      "   [-0.75512075  0.31545717  0.30184372]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.44096859 -0.27671895 -1.08373245]\n",
      "   [-0.84256807  0.20531414  0.47261163]]\n",
      "\n",
      "  [[-0.63653715 -0.29927773 -0.06289737]\n",
      "   [-0.48540104 -0.34226717 -1.01615171]\n",
      "   [-0.88200358  0.16735452  0.62158891]]\n",
      "\n",
      "  [[-0.63653715 -0.29927773 -0.06289737]\n",
      "   [-0.47125663 -0.3060434  -1.05258558]\n",
      "   [-0.83395614  0.18276455  0.41688913]]\n",
      "\n",
      "  [[-0.69470468 -0.23749316 -0.09688995]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.84730751  0.29522046  0.43549617]]\n",
      "\n",
      "  [[-0.69470468 -0.23749316 -0.09688995]\n",
      "   [-0.4923069  -0.39078447 -1.02154618]\n",
      "   [-0.79243077  0.28605396  0.44768685]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.47171953 -0.33605965 -0.98992597]\n",
      "   [-0.84545767  0.01536794  0.48285305]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.47171953 -0.33605965 -0.98992597]\n",
      "   [-0.90701356  0.23953572  0.52233481]]\n",
      "\n",
      "  [[-0.67109221 -0.30773201 -0.0278013 ]\n",
      "   [-0.50601159 -0.33033158 -0.99754384]\n",
      "   [-0.89938586  0.14914695  0.56009189]]\n",
      "\n",
      "  [[-0.67109221 -0.30773201 -0.0278013 ]\n",
      "   [-0.49810333 -0.277779   -0.99362744]\n",
      "   [-0.89744475  0.21448063  0.46042095]]\n",
      "\n",
      "  [[-0.64764707 -0.24535356 -0.08643626]\n",
      "   [-0.48540104 -0.34226717 -1.01615171]\n",
      "   [-0.89646058  0.28231982  0.36694137]]\n",
      "\n",
      "  [[-0.64764707 -0.24535356 -0.08643626]\n",
      "   [-0.50200758 -0.3653841  -0.95877911]\n",
      "   [-0.89646058  0.28231982  0.36694137]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.46435076 -0.25752611 -1.04719111]\n",
      "   [-0.86856228  0.20965616  0.4668371 ]]]\n",
      "\n",
      "\n",
      " [[[-0.61930145 -0.26189627 -0.11237629]\n",
      "   [-0.48886556 -0.33319561 -0.99373491]\n",
      "   [-0.85521092  0.09720026  0.44823007]]\n",
      "\n",
      "  [[-0.61930145 -0.26189627 -0.11237629]\n",
      "   [-0.50254706 -0.33940313 -1.01996065]\n",
      "   [-0.85213688  0.23036923  0.53452548]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.48496131 -0.24559051 -1.02858324]\n",
      "   [-0.93976992 -0.0134252   0.61963966]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.47093336 -0.24029015 -1.00459917]\n",
      "   [-0.8743402   0.02019242  0.4764369 ]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.47125663 -0.3060434  -1.05258558]\n",
      "   [-0.82912678  0.24761581  0.31785987]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.48496131 -0.24559051 -1.02858324]\n",
      "   [-0.92712707  0.0946887   0.64402121]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.49498525 -0.2859434  -1.01380257]\n",
      "   [-0.85995035  0.18710657  0.41111461]]\n",
      "\n",
      "  [[-0.67109221 -0.30773201 -0.0278013 ]\n",
      "   [-0.45432682 -0.21717322 -1.06197177]\n",
      "   [-0.88594322  0.38187727  0.39445702]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.88674301  0.25726083  0.58447345]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.88883282  0.19193104  0.40469846]]\n",
      "\n",
      "  [[-0.6241183  -0.24928376 -0.08120942]\n",
      "   [-0.43094465 -0.23636607 -1.09851311]\n",
      "   [-0.89744475  0.21448063  0.46042095]]\n",
      "\n",
      "  [[-0.64903965 -0.28296305 -0.10844711]\n",
      "   [-0.47827895 -0.3854841  -0.99756211]\n",
      "   [-0.91851514  0.07213911  0.58829872]]\n",
      "\n",
      "  [[-0.64903965 -0.28296305 -0.10844711]\n",
      "   [-0.51657501 -0.3447035  -1.04394471]\n",
      "   [-0.90894634  0.04708402  0.52638486]]\n",
      "\n",
      "  [[-0.64283022 -0.25796607 -0.11760313]\n",
      "   [-0.46835477 -0.22247359 -1.08595584]\n",
      "   [-0.94739762  0.07696358  0.58188257]]\n",
      "\n",
      "  [[-0.68832791 -0.34511348  0.02167763]\n",
      "   [-0.48840265 -0.30317936 -1.05639451]\n",
      "   [-0.88981705  0.12409186  0.49817803]]\n",
      "\n",
      "  [[-0.68832791 -0.34511348  0.02167763]\n",
      "   [-0.45432682 -0.21717322 -1.06197177]\n",
      "   [-0.90894634  0.04708402  0.52638486]]\n",
      "\n",
      "  [[-0.6241183  -0.24928376 -0.08120942]\n",
      "   [-0.47147285 -0.21430918 -1.06578071]\n",
      "   [-0.90894634  0.04708402  0.52638486]]\n",
      "\n",
      "  [[-0.6241183  -0.24928376 -0.08120942]\n",
      "   [-0.4809573  -0.28064303 -0.9898185 ]\n",
      "   [-0.88674301  0.25726083  0.58447345]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 864, 18, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(11)\n",
    "np.random.seed(11)\n",
    "torch.manual_seed(11)\n",
    "\n",
    "theta = random.random()*math.pi*2\n",
    "theta = random.random()*360\n",
    "a=random.random()\n",
    "b=random.random()\n",
    "c=random.random()\n",
    "\n",
    "print(model_input[0,:2,:,:])\n",
    "print()\n",
    "tmp=rotateC(model_input.cpu().detach().numpy(),theta,a,b,c)\n",
    "print(tmp[0,:2,:,:])\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ratio of two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 2, 6],\n",
       "         [8, 3, 1],\n",
       "         [3, 7, 4],\n",
       "         [8, 1, 5]], device='cuda:3'),\n",
       " tensor([[4, 8, 3, 8],\n",
       "         [2, 3, 7, 1],\n",
       "         [6, 1, 4, 5]], device='cuda:3'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a= torch.randint(0,9, size=(4,3)).to(\"cuda:3\")\n",
    "a, a.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23288"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib, torch\n",
    "\n",
    "all_dpath = \"data/rectified_data/kaggle_pd_data/train_kaggle_pd_data_blks15552_ps18_randomaug.p\"\n",
    "all_data = joblib.load(all_dpath)\n",
    "len(all_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2402, 2402)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for key, value in all_data.items():\n",
    "    if value['series_name'] in a:\n",
    "        count += 1\n",
    "count, len(all_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([864, 3]),\n",
       " tensor([[1., 0., 0.],\n",
       "         [1., 0., 0.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[3]['gt'].shape, all_data[3]['gt'][:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one:  2059578\n",
      "zero:  4901310\n",
      "two:  13154766\n",
      "zero to one:  2.379764204123369\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the ratio\n",
    "def calculate_class_ratio(train_data):\n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    twos = 0\n",
    "    for example_id, example_data in train_data.items():\n",
    "        gt = example_data['gt']\n",
    "        num_zeros = torch.sum(gt[:,0] == 1).item()\n",
    "        num_ones = torch.sum(gt[:,1] == 1).item()\n",
    "        num_twos = torch.sum(gt[:,2] == 1).item()\n",
    "        ones += num_ones\n",
    "        zeros += num_zeros\n",
    "        twos += num_twos\n",
    "    print(\"one: \", ones)\n",
    "    print(\"zero: \", zeros)\n",
    "    print(\"two: \", twos)\n",
    "    print(\"zero to one: \", zeros / ones)\n",
    "\n",
    "# Calculate the ratio for the training data\n",
    "calculate_class_ratio(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3, -9],\n",
       "         [ 5, -9],\n",
       "         [ 6, -9]]),\n",
       " tensor([[3, 8],\n",
       "         [5, 2],\n",
       "         [6, 8]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randint(0, 9, (3, 2))\n",
    "b = a.clone()\n",
    "a[:, 1] = -9\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125387    2.0\n",
      "125388    2.0\n",
      "125389    2.0\n",
      "Name: GroundTruth_Trial44, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path and the column name\n",
    "file_path = 'data/rectified_data/kaggle_pd_data/defog/gt_kaggle_pd_data.csv'\n",
    "column_name = 'GroundTruth_Trial44'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the specific column\n",
    "column_data = df[column_name]\n",
    "\n",
    "# Print rows 10 to 25 (index 9 to 24) of the column\n",
    "print(column_data.iloc[125387:125390])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
