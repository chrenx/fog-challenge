{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the autoencoder model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #* Encoding layers *************************************************************************\n",
    "        self.e11 = nn.Conv1d(channel, 32, kernel_size=3, padding='same')\n",
    "        self.e12 = nn.Conv1d(32, 32, kernel_size=3, padding='same')\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2) # 1024\n",
    "        \n",
    "        self.e21 = nn.Conv1d(32, 64, kernel_size=3, padding='same')\n",
    "        self.e22 = nn.Conv1d(64, 64, kernel_size=3, padding='same')\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2) # 512\n",
    "        \n",
    "        self.e31 = nn.Conv1d(64, 128, kernel_size=3, padding='same')\n",
    "        self.e32 = nn.Conv1d(128, 128, kernel_size=3, padding='same')\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2) # 256\n",
    "        \n",
    "        self.e41 = nn.Conv1d(128, 256, kernel_size=3, padding='same')\n",
    "        self.e42 = nn.Conv1d(256, 256, kernel_size=3, padding='same')\n",
    "        self.maxpool4 = nn.MaxPool1d(kernel_size=2) # 128\n",
    "        \n",
    "        self.e51 = nn.Conv1d(256, 512, kernel_size=3, padding='same')\n",
    "        self.e52 = nn.Conv1d(512, 512, kernel_size=3, padding='same') #128*512\n",
    "        self.maxpool5 = nn.MaxPool1d(kernel_size=2) # 64\n",
    "\n",
    "        #* Decoding layers *************************************************************************\n",
    "        self.d51 = nn.Conv1d(512, 512, kernel_size=3, padding='same')\n",
    "        self.d52 = nn.Conv1d(512, 512, kernel_size=3, padding='same')\n",
    "        self.up5 = nn.ConvTranspose1d(512, 512, kernel_size=2, stride=2, padding=0)\n",
    "        # cat: up5, e52: 512 + 512 = 1024\n",
    "        \n",
    "        self.d41 = nn.Conv1d(1024, 256, kernel_size=3, padding='same')\n",
    "        self.d42 = nn.Conv1d(256, 256, kernel_size=3, padding='same')\n",
    "        self.up4 = nn.ConvTranspose1d(256, 512, kernel_size=2, stride=2, padding=0)\n",
    "        # cat: up4, e42: 512 + 256 = 768\n",
    "        \n",
    "        self.d31 = nn.Conv1d(768, 128, kernel_size=3, padding='same')\n",
    "        self.d32 = nn.Conv1d(128, 128, kernel_size=3, padding='same')\n",
    "        self.up3 = nn.ConvTranspose1d(128, 512, kernel_size=2, stride=2, padding=0)\n",
    "        # cat: up3, e32: 512 + 128 = 640\n",
    "        \n",
    "        self.d21 = nn.Conv1d(640, 64, kernel_size=3, padding='same')\n",
    "        self.d22 = nn.Conv1d(64, 64, kernel_size=3, padding='same')\n",
    "        self.up2 = nn.ConvTranspose1d(64, 512, kernel_size=2, stride=2, padding=0)\n",
    "        # cat: up2, e22: 512 + 64 = 576\n",
    "        \n",
    "        self.d11 = nn.Conv1d(576, 64, kernel_size=3, padding='same')\n",
    "        self.d12 = nn.Conv1d(64, 64, kernel_size=3, padding='same')\n",
    "        self.up1 = nn.ConvTranspose1d(64, 512, kernel_size=2, stride=2, padding=0)\n",
    "        # cat: up1, e12: 512 + 32 = 544\n",
    "        \n",
    "        self.outconv = nn.Conv1d(544, 2, kernel_size=3, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,num_feats,L)\n",
    "        \n",
    "        #* Encoding layers *************************************************************************\n",
    "        xe11 = self.relu(self.e11(x))\n",
    "        xe12 = self.relu(self.e12(xe11))\n",
    "        xp1 = self.maxpool1(xe12)\n",
    "        \n",
    "        xe21 = self.relu(self.e21(xp1))\n",
    "        xe22 = self.relu(self.e22(xe21))\n",
    "        xp2 = self.maxpool2(xe22)\n",
    "        \n",
    "        xe31 = self.relu(self.e31(xp2))\n",
    "        xe32 = self.relu(self.e32(xe31))\n",
    "        xp3 = self.maxpool3(xe32)\n",
    "        \n",
    "        xe41 = self.relu(self.e41(xp3))\n",
    "        xe42 = self.relu(self.e42(xe41))\n",
    "        xp4 = self.maxpool4(xe42)\n",
    "        \n",
    "        xe51 = self.relu(self.e51(xp4))\n",
    "        xe52 = self.relu(self.e52(xe51))\n",
    "        xp5 = self.maxpool5(xe52)\n",
    "        \n",
    "        #* Decoding layers *************************************************************************\n",
    "        xd51 = self.relu(self.d51(xp5))\n",
    "        xd52 = self.relu(self.d52(xd51))\n",
    "        xup5 = self.relu(self.up5(xd52))\n",
    "        xup5 = torch.cat([xup5, xe52], dim=-2)\n",
    "        \n",
    "        xd41 = self.relu(self.d41(xup5))\n",
    "        xd42 = self.relu(self.d42(xd41))\n",
    "        xup4 = self.relu(self.up4(xd42))\n",
    "        xup4 = torch.cat([xup4, xe42], dim=-2)\n",
    "        \n",
    "        xd31 = self.relu(self.d31(xup4))\n",
    "        xd32 = self.relu(self.d32(xd31))\n",
    "        xup3 = self.relu(self.up3(xd32))\n",
    "        xup3 = torch.cat([xup3, xe32], dim=-2)\n",
    "        \n",
    "        xd21 = self.relu(self.d21(xup3))\n",
    "        xd22 = self.relu(self.d22(xd21))\n",
    "        xup2 = self.relu(self.up2(xd22))\n",
    "        xup2 = torch.cat([xup2, xe22], dim=-2)\n",
    "        \n",
    "        xd11 = self.relu(self.d11(xup2))\n",
    "        xd12 = self.relu(self.d12(xd11))\n",
    "        xup1 = self.relu(self.up1(xd12))\n",
    "        xup1 = torch.cat([xup1, xe12], dim=-2)\n",
    "        \n",
    "        decoding = self.outconv(xup1)\n",
    "        \n",
    "        return decoding # (B,num_class,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_data = torch.rand(size=(1,3,2047))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 126 but got size 127 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m UNet(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m output\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/local/disk4/chrenx/conda-env/envs/fog/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/disk4/chrenx/conda-env/envs/fog/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[85], line 90\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m xd52 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md52(xd51))\n\u001b[1;32m     89\u001b[0m xup5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup5(xd52))\n\u001b[0;32m---> 90\u001b[0m xup5 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxup5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxe52\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m xd41 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md41(xup5))\n\u001b[1;32m     93\u001b[0m xd42 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md42(xd41))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 126 but got size 127 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "model = UNet(3)\n",
    "output = model(input_data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original gt:\n",
      "tensor([[[0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [1., 0., 0.]]])\n",
      "tensor([[[1],\n",
      "         [0],\n",
      "         [2],\n",
      "         [1],\n",
      "         [0]],\n",
      "\n",
      "        [[2],\n",
      "         [1],\n",
      "         [0],\n",
      "         [2],\n",
      "         [0]]])\n",
      "\n",
      "Converted output:\n",
      "tensor([[[1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [1.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "B = 2\n",
    "window = 5\n",
    "gt = torch.tensor([\n",
    "    [[0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0]],\n",
    "    [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0]]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Find the index of the max value in the last dimension\n",
    "max_indices = torch.argmax(gt, dim=2, keepdim=True)\n",
    "\n",
    "# Create the output tensor with shape (B, window, 1)\n",
    "mask = (max_indices != 2).float()\n",
    "\n",
    "print(\"Original gt:\")\n",
    "print(gt)\n",
    "print(max_indices)\n",
    "print(\"\\nConverted output:\")\n",
    "print(max_indices * mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameterts in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count the number of parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    \"\"\"A dictionary with dot notation access to attributes.\"\"\"\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "    def __delattr__(self, key):\n",
    "        try:\n",
    "            del self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
    "        \n",
    "# Function to convert existing dictionary to DotDict\n",
    "def dict_to_dotdict(d):\n",
    "    if not isinstance(d, dict):\n",
    "        return d\n",
    "    return DotDict({k: dict_to_dotdict(v) if isinstance(v, dict) else v for k, v in d.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerBiLSTM Total parameters: 7486402\n",
      "TransformerBiLSTM Trainable parameters: 7486402\n",
      "Transformer Total parameters: 3379522\n",
      "Transformer Trainable parameters: 3379522\n"
     ]
    }
   ],
   "source": [
    "from models.transformer_bilstm_v2 import TransformerBiLSTM\n",
    "from models.transformer_v1 import Transformer\n",
    "opt = {\n",
    "    'block_size': 15552,\n",
    "    'block_stride': 972,\n",
    "    'patch_size': 18,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'fog_model_input_dim': 54,\n",
    "    'fog_model_dim': 320,\n",
    "    'fog_model_num_heads': 8,\n",
    "    'fog_model_num_encoder_layers': 5,\n",
    "    'fog_model_num_lstm_layers': 2,\n",
    "    'fog_model_first_dropout': 0.1,\n",
    "    'fog_model_encoder_dropout': 0.1,\n",
    "    'fog_model_mha_dropout': 0.0,\n",
    "}\n",
    "\n",
    "opt = DotDict(opt)\n",
    "\n",
    "model = TransformerBiLSTM(opt)\n",
    "transformer_model = Transformer(opt)\n",
    "\n",
    "# Get the total and trainable parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "print(f\"TransformerBiLSTM Total parameters: {total_params}\")\n",
    "print(f\"TransformerBiLSTM Trainable parameters: {trainable_params}\")\n",
    "\n",
    "total_params, trainable_params = count_parameters(transformer_model)\n",
    "\n",
    "print(f\"Transformer Total parameters: {total_params}\")\n",
    "print(f\"Transformer Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "dict_keys(['series_name', 'start_t_idx', 'end_t_idx', 'model_input', 'gt'])\n",
      "rectified_16_dataset_fog_release\n",
      "torch.Size([15552])\n",
      "tensor([2, 2, 2], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "import joblib, random, torch\n",
    "\n",
    "random.seed(11)\n",
    "pickle_path = \"data/rectified_data/dataset_fog_release/val_dataset_fog_release.p\"\n",
    "\n",
    "all_data = joblib.load(pickle_path)\n",
    "\n",
    "print(len(all_data.keys()))\n",
    "print(all_data[200].keys())\n",
    "\n",
    "gt = all_data[200]['gt']\n",
    "print(all_data[200]['series_name'])\n",
    "print(gt.shape)\n",
    "print(gt[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]),\n",
       " tensor([[1.7707, 2.4249, 0.1701, 0.8715, 2.5939, 1.6950],\n",
       "         [1.1421, 0.6567, 0.1020, 0.8278, 0.0357, 1.0962]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "bce = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "pred = torch.rand(2,6)\n",
    "mask = torch.tensor([[0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 1]]).float()\n",
    "\n",
    "loss = bce(pred, mask)\n",
    "loss.shape, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictToObj:\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        return self.__dict__.get(name)\n",
    "    \n",
    "opt = {\n",
    "    'seed': 11,\n",
    "    'optimizer': 'adamw',\n",
    "    'learning_rate': 0.00026,\n",
    "    'adam_betas': (0.9, 0.98),\n",
    "    'adam_eps': 1.0e-09,\n",
    "    'weight_decay': 0,\n",
    "    'lr_scheduler_factor': 0.1,\n",
    "    'lr_scheduler_patience': 20,\n",
    "    'lr_scheduler_warmup_steps': 64,\n",
    "    'train_num_steps': 20000,\n",
    "    'penalty_cost': 2.0,\n",
    "    'block_size': 15552,\n",
    "    'block_stride': 972,\n",
    "    'patch_size': 18,\n",
    "    'fog_model_input_dim': 162,\n",
    "    'fog_model_dim': 320,\n",
    "    'fog_model_num_heads': 8,\n",
    "    'fog_model_num_encoder_layers': 5,\n",
    "    'fog_model_num_lstm_layers': 2,\n",
    "    'fog_model_first_dropout': 0.1,\n",
    "    'fog_model_encoder_dropout': 0.1,\n",
    "    'fog_model_mha_dropout': 0.0,\n",
    "}\n",
    "opt = DictToObj(opt)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from models.transformer_bilstm_v1 import TransformerBiLSTM\n",
    "\n",
    "random.seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "model = TransformerBiLSTM(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from data.fog_dataset_v1 import FoGDataset\n",
    "\n",
    "train_dpath = \"data/rectified_data/dataset_fog_release/train1_dataset_fog_release_blks15552_ps18.p\"\n",
    "model_path = \"runs/train/transfomer_bilstm/2024_06_12_21:12:41.10/weights/model_regular_19991.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path)['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1055,\n",
       " dict_keys(['series_name', 'start_t_idx', 'end_t_idx', 'model_input', 'gt']),\n",
       " torch.Size([864, 162]),\n",
       " torch.Size([864, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "train_ds = joblib.load(train_dpath)\n",
    "len(train_ds.keys()), train_ds[1].keys(), train_ds[1]['model_input'].shape, train_ds[1]['gt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 864, 162]), torch.Size([32, 864, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = []\n",
    "gt = []\n",
    "for i in range(32):\n",
    "    model_input.append(train_ds[i]['model_input'][None, :, :])\n",
    "    gt.append(train_ds[i]['gt'][None, :, :])\n",
    "\n",
    "model_input= torch.cat(model_input, dim=0)\n",
    "gt = torch.cat(gt, dim=0)\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 864, 162]), torch.Size([32, 864, 3]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.fog_dataset_v1 import FoGDataset\n",
    "\n",
    "val_dpath = \"data/rectified_data/dataset_fog_release/val1_dataset_fog_release_blks15552_ps18.p\"\n",
    "model_path = \"runs/train/transfomer_bilstm/2024_06_12_21:12:41.10/weights/model_regular_19991.pt\"\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(model_path)['model'])\n",
    "import joblib\n",
    "val_ds = joblib.load(val_dpath)\n",
    "\n",
    "model_input = []\n",
    "gt = []\n",
    "for i in range(32):\n",
    "    model_input.append(val_ds[i]['model_input'][None, :, :])\n",
    "    gt.append(val_ds[i]['gt'][None, :, :])\n",
    "\n",
    "model_input= torch.cat(model_input, dim=0)\n",
    "gt = torch.cat(gt, dim=0)\n",
    "\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7070),\n",
       " tensor(0.5953),\n",
       " tensor(0.6464),\n",
       " tensor(0.4415),\n",
       " tensor(4.1332, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(model_input)\n",
    "loss = loss_func(pred, gt)\n",
    "precision, recall, f1, ap = evaluation_metrics(pred, gt)\n",
    "precision, recall, f1, ap, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def norm_axis(a,b,c):\n",
    "    newa=a/(math.sqrt(float(a*a+b*b+c*c)))\n",
    "    newb=b/(math.sqrt(float(a*a+b*b+c*c)))\n",
    "    newc=c/(math.sqrt(float(a*a+b*b+c*c)))\n",
    "    return ([newa,newb,newc])\n",
    "\n",
    "def rotation_matrix(axis, theta):\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis/math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta/2.0)\n",
    "    b, c, d = -axis*math.sin(theta/2.0)\n",
    "    aa, bb, cc, dd = a*a, b*b, c*c, d*d\n",
    "    bc, ad, ac, ab, bd, cd = b*c, a*d, a*c, a*b, b*d, c*d\n",
    "    return np.array([[aa+bb-cc-dd, 2*(bc+ad), 2*(bd-ac)], \n",
    "                     [2*(bc-ad), aa+cc-bb-dd, 2*(cd+ab)], \n",
    "                     [2*(bd+ac), 2*(cd-ab), aa+dd-bb-cc]])\n",
    "\n",
    "def rotateC(image,theta,a,b,c): ## theta: angle, a, b, c, eular vector\n",
    "    axis=norm_axis(a,b,c)\n",
    "    imagenew=np.dot(image, rotation_matrix(axis,theta))\n",
    "    return imagenew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 864, 162]), torch.Size([32, 864, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.fog_dataset_v1 import FoGDataset\n",
    "\n",
    "train_dpath = \"data/rectified_data/dataset_fog_release/train1_dataset_fog_release_blks15552_ps18.p\"\n",
    "import joblib\n",
    "train_ds = joblib.load(train_dpath)\n",
    "\n",
    "model_input = []\n",
    "gt = []\n",
    "for i in range(32):\n",
    "    model_input.append(train_ds[i]['model_input'][None, :, :])\n",
    "    gt.append(train_ds[i]['gt'][None, :, :])\n",
    "\n",
    "model_input= torch.cat(model_input, dim=0)\n",
    "gt = torch.cat(gt, dim=0)\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 864, 18, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = model_input.reshape(32,864, 18, 9)\n",
    "model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 864, 18, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = model_input.reshape(32, 864, 18, 3, 3)\n",
    "model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3),\n",
       " array([[ 0.38501953, -0.68464825,  0.61888345],\n",
       "        [ 0.91940947,  0.22620226, -0.32174332],\n",
       "        [ 0.08028816,  0.69288477,  0.71656438]]),\n",
       " 215.03446095139176)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "theta = random.random()*math.pi*2\n",
    "theta = random.random()*360\n",
    "a=random.random()\n",
    "b=random.random()\n",
    "c=random.random()\n",
    "axis=norm_axis(a,b,c)\n",
    "tmp = rotation_matrix(axis,theta)\n",
    "tmp.shape, tmp, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.6030, -0.3699, -0.0446],\n",
      "          [-0.6301, -0.0343, -1.0127],\n",
      "          [-0.6837,  0.2872,  0.8251]],\n",
      "\n",
      "         [[-0.6274, -0.3699, -0.0446],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.6837,  0.0158,  0.6969]],\n",
      "\n",
      "         [[-0.6274, -0.3699, -0.0446],\n",
      "          [-0.6479,  0.0539, -0.9907],\n",
      "          [-0.7707, -0.0684,  0.6969]],\n",
      "\n",
      "         [[-0.5542, -0.3425, -0.1125],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.0684,  0.6969]],\n",
      "\n",
      "         [[-0.5542, -0.3425, -0.1125],\n",
      "          [-0.6301, -0.0343, -0.9443],\n",
      "          [-0.7137,  0.0158,  0.5687]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6301,  0.0098, -0.9907],\n",
      "          [-0.7137,  0.0158,  0.5012]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6123,  0.0098, -1.0347],\n",
      "          [-0.7437, -0.1619,  0.6294]],\n",
      "\n",
      "         [[-0.5786, -0.3972, -0.0786],\n",
      "          [-0.6301, -0.0829, -0.9907],\n",
      "          [-0.7437, -0.2555,  0.7576]],\n",
      "\n",
      "         [[-0.5786, -0.3972, -0.0786],\n",
      "          [-0.6301, -0.0343, -1.0127],\n",
      "          [-0.7437, -0.1619,  0.5687]],\n",
      "\n",
      "         [[-0.6518, -0.3425, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.0684,  0.6294]],\n",
      "\n",
      "         [[-0.6518, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.1270, -1.0127],\n",
      "          [-0.7137, -0.0684,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6123, -0.0829, -0.9663],\n",
      "          [-0.7137, -0.3397,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6123, -0.0829, -0.9663],\n",
      "          [-0.8006, -0.1619,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.4245, -0.0446],\n",
      "          [-0.6479, -0.0829, -0.9663],\n",
      "          [-0.7707, -0.2555,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.4245, -0.0446],\n",
      "          [-0.6479, -0.0343, -0.9443],\n",
      "          [-0.8006, -0.1619,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.0829, -0.9907],\n",
      "          [-0.8306, -0.0684,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.1270, -0.9443],\n",
      "          [-0.8306, -0.0684,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6301,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.1619,  0.6294]]],\n",
      "\n",
      "\n",
      "        [[[-0.5786, -0.3425, -0.1125],\n",
      "          [-0.6301, -0.0829, -0.9663],\n",
      "          [-0.7437, -0.2555,  0.5687]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.1125],\n",
      "          [-0.6479, -0.0829, -0.9907],\n",
      "          [-0.7437, -0.1619,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9663],\n",
      "          [-0.7707, -0.4333,  0.6969]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6301,  0.0098, -0.9443],\n",
      "          [-0.7437, -0.3397,  0.5687]],\n",
      "\n",
      "         [[-0.5542, -0.3972, -0.0786],\n",
      "          [-0.6301, -0.0343, -1.0127],\n",
      "          [-0.7707, -0.0684,  0.5012]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6479,  0.0098, -0.9663],\n",
      "          [-0.7707, -0.3397,  0.7576]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.0446],\n",
      "          [-0.6479, -0.0343, -0.9663],\n",
      "          [-0.7707, -0.1619,  0.5687]],\n",
      "\n",
      "         [[-0.6030, -0.4245, -0.0446],\n",
      "          [-0.6301,  0.0539, -0.9907],\n",
      "          [-0.8306,  0.0158,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.7707, -0.1619,  0.7576]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.0786],\n",
      "          [-0.6479,  0.0098, -0.9907],\n",
      "          [-0.8006, -0.1619,  0.5687]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.0786],\n",
      "          [-0.6123,  0.0539, -1.0347],\n",
      "          [-0.8006, -0.1619,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.1125],\n",
      "          [-0.6123, -0.1270, -0.9907],\n",
      "          [-0.7707, -0.3397,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.3699, -0.1125],\n",
      "          [-0.6657, -0.0829, -1.0127],\n",
      "          [-0.7707, -0.3397,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.3425, -0.1125],\n",
      "          [-0.6479,  0.0539, -1.0127],\n",
      "          [-0.8006, -0.3397,  0.6969]],\n",
      "\n",
      "         [[-0.6030, -0.4792, -0.0106],\n",
      "          [-0.6479, -0.0343, -1.0127],\n",
      "          [-0.7707, -0.2555,  0.6294]],\n",
      "\n",
      "         [[-0.6030, -0.4792, -0.0106],\n",
      "          [-0.6301,  0.0539, -0.9907],\n",
      "          [-0.7707, -0.3397,  0.6294]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.0786],\n",
      "          [-0.6479,  0.0539, -0.9907],\n",
      "          [-0.7707, -0.3397,  0.6294]],\n",
      "\n",
      "         [[-0.5786, -0.3425, -0.0786],\n",
      "          [-0.6301, -0.0343, -0.9443],\n",
      "          [-0.7707, -0.1619,  0.7576]]]])\n",
      "\n",
      "[[[[-0.65867335 -0.25773804 -0.04611335]\n",
      "   [-0.47125663 -0.3060434  -1.05258558]\n",
      "   [-0.71052971  0.67903355  0.51455767]]\n",
      "\n",
      "  [[-0.68220213 -0.25380784 -0.05134019]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.75398781  0.38329243  0.48781002]]\n",
      "\n",
      "  [[-0.68220213 -0.25380784 -0.05134019]\n",
      "   [-0.47147285 -0.21430918 -1.06578071]\n",
      "   [-0.85687631  0.32027554  0.49741002]]\n",
      "\n",
      "  [[-0.59577262 -0.26582648 -0.10714944]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.85687631  0.32027554  0.49741002]]\n",
      "\n",
      "  [[-0.59577262 -0.26582648 -0.10714944]\n",
      "   [-0.4809573  -0.28064303 -0.9898185 ]\n",
      "   [-0.76468955  0.34051223  0.36375752]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.46435076 -0.25752611 -1.04719111]\n",
      "   [-0.75512075  0.31545717  0.30184372]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.44096859 -0.27671895 -1.08373245]\n",
      "   [-0.84256807  0.20531414  0.47261163]]\n",
      "\n",
      "  [[-0.63653715 -0.29927773 -0.06289737]\n",
      "   [-0.48540104 -0.34226717 -1.01615171]\n",
      "   [-0.88200358  0.16735452  0.62158891]]\n",
      "\n",
      "  [[-0.63653715 -0.29927773 -0.06289737]\n",
      "   [-0.47125663 -0.3060434  -1.05258558]\n",
      "   [-0.83395614  0.18276455  0.41688913]]\n",
      "\n",
      "  [[-0.69470468 -0.23749316 -0.09688995]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.84730751  0.29522046  0.43549617]]\n",
      "\n",
      "  [[-0.69470468 -0.23749316 -0.09688995]\n",
      "   [-0.4923069  -0.39078447 -1.02154618]\n",
      "   [-0.79243077  0.28605396  0.44768685]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.47171953 -0.33605965 -0.98992597]\n",
      "   [-0.84545767  0.01536794  0.48285305]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.47171953 -0.33605965 -0.98992597]\n",
      "   [-0.90701356  0.23953572  0.52233481]]\n",
      "\n",
      "  [[-0.67109221 -0.30773201 -0.0278013 ]\n",
      "   [-0.50601159 -0.33033158 -0.99754384]\n",
      "   [-0.89938586  0.14914695  0.56009189]]\n",
      "\n",
      "  [[-0.67109221 -0.30773201 -0.0278013 ]\n",
      "   [-0.49810333 -0.277779   -0.99362744]\n",
      "   [-0.89744475  0.21448063  0.46042095]]\n",
      "\n",
      "  [[-0.64764707 -0.24535356 -0.08643626]\n",
      "   [-0.48540104 -0.34226717 -1.01615171]\n",
      "   [-0.89646058  0.28231982  0.36694137]]\n",
      "\n",
      "  [[-0.64764707 -0.24535356 -0.08643626]\n",
      "   [-0.50200758 -0.3653841  -0.95877911]\n",
      "   [-0.89646058  0.28231982  0.36694137]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.46435076 -0.25752611 -1.04719111]\n",
      "   [-0.86856228  0.20965616  0.4668371 ]]]\n",
      "\n",
      "\n",
      " [[[-0.61930145 -0.26189627 -0.11237629]\n",
      "   [-0.48886556 -0.33319561 -0.99373491]\n",
      "   [-0.85521092  0.09720026  0.44823007]]\n",
      "\n",
      "  [[-0.61930145 -0.26189627 -0.11237629]\n",
      "   [-0.50254706 -0.33940313 -1.01996065]\n",
      "   [-0.85213688  0.23036923  0.53452548]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.48496131 -0.24559051 -1.02858324]\n",
      "   [-0.93976992 -0.0134252   0.61963966]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.47093336 -0.24029015 -1.00459917]\n",
      "   [-0.8743402   0.02019242  0.4764369 ]]\n",
      "\n",
      "  [[-0.61300832 -0.30320794 -0.05767051]\n",
      "   [-0.47125663 -0.3060434  -1.05258558]\n",
      "   [-0.82912678  0.24761581  0.31785987]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.48496131 -0.24559051 -1.02858324]\n",
      "   [-0.92712707  0.0946887   0.64402121]]\n",
      "\n",
      "  [[-0.65246393 -0.23274106 -0.05526937]\n",
      "   [-0.49498525 -0.2859434  -1.01380257]\n",
      "   [-0.85995035  0.18710657  0.41111461]]\n",
      "\n",
      "  [[-0.67109221 -0.30773201 -0.0278013 ]\n",
      "   [-0.45432682 -0.21717322 -1.06197177]\n",
      "   [-0.88594322  0.38187727  0.39445702]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.88674301  0.25726083  0.58447345]]\n",
      "\n",
      "  [[-0.6538565  -0.27035055 -0.07728023]\n",
      "   [-0.48149679 -0.25466207 -1.05100004]\n",
      "   [-0.88883282  0.19193104  0.40469846]]\n",
      "\n",
      "  [[-0.6241183  -0.24928376 -0.08120942]\n",
      "   [-0.43094465 -0.23636607 -1.09851311]\n",
      "   [-0.89744475  0.21448063  0.46042095]]\n",
      "\n",
      "  [[-0.64903965 -0.28296305 -0.10844711]\n",
      "   [-0.47827895 -0.3854841  -0.99756211]\n",
      "   [-0.91851514  0.07213911  0.58829872]]\n",
      "\n",
      "  [[-0.64903965 -0.28296305 -0.10844711]\n",
      "   [-0.51657501 -0.3447035  -1.04394471]\n",
      "   [-0.90894634  0.04708402  0.52638486]]\n",
      "\n",
      "  [[-0.64283022 -0.25796607 -0.11760313]\n",
      "   [-0.46835477 -0.22247359 -1.08595584]\n",
      "   [-0.94739762  0.07696358  0.58188257]]\n",
      "\n",
      "  [[-0.68832791 -0.34511348  0.02167763]\n",
      "   [-0.48840265 -0.30317936 -1.05639451]\n",
      "   [-0.88981705  0.12409186  0.49817803]]\n",
      "\n",
      "  [[-0.68832791 -0.34511348  0.02167763]\n",
      "   [-0.45432682 -0.21717322 -1.06197177]\n",
      "   [-0.90894634  0.04708402  0.52638486]]\n",
      "\n",
      "  [[-0.6241183  -0.24928376 -0.08120942]\n",
      "   [-0.47147285 -0.21430918 -1.06578071]\n",
      "   [-0.90894634  0.04708402  0.52638486]]\n",
      "\n",
      "  [[-0.6241183  -0.24928376 -0.08120942]\n",
      "   [-0.4809573  -0.28064303 -0.9898185 ]\n",
      "   [-0.88674301  0.25726083  0.58447345]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 864, 18, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(11)\n",
    "np.random.seed(11)\n",
    "torch.manual_seed(11)\n",
    "\n",
    "theta = random.random()*math.pi*2\n",
    "theta = random.random()*360\n",
    "a=random.random()\n",
    "b=random.random()\n",
    "c=random.random()\n",
    "\n",
    "print(model_input[0,:2,:,:])\n",
    "print()\n",
    "tmp=rotateC(model_input.cpu().detach().numpy(),theta,a,b,c)\n",
    "print(tmp[0,:2,:,:])\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check ratio of two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 2, 6],\n",
       "         [8, 3, 1],\n",
       "         [3, 7, 4],\n",
       "         [8, 1, 5]], device='cuda:3'),\n",
       " tensor([[4, 8, 3, 8],\n",
       "         [2, 3, 7, 1],\n",
       "         [6, 1, 4, 5]], device='cuda:3'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a= torch.randint(0,9, size=(4,3)).to(\"cuda:3\")\n",
    "a, a.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib, torch\n",
    "\n",
    "all_dpath = \"data/rectified_data/kaggle_pd_data/all_kaggle_pd_data.p\"\n",
    "all_data = joblib.load(all_dpath)\n",
    "len(all_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one:  3376251\n",
      "zero:  11171255\n",
      "two:  16017982\n",
      "zero to one:  3.3087750288707802\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the ratio\n",
    "def calculate_class_ratio(train_data):\n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    twos = 0\n",
    "    for example_id, example_data in train_data.items():\n",
    "        gt = example_data['gt']\n",
    "        num_zeros = torch.sum(gt == 0).item()\n",
    "        num_ones = torch.sum(gt == 1).item()\n",
    "        num_twos = torch.sum(gt == 2).item()\n",
    "        ones += num_ones\n",
    "        zeros += num_zeros\n",
    "        twos += num_twos\n",
    "    print(\"one: \", ones)\n",
    "    print(\"zero: \", zeros)\n",
    "    print(\"two: \", twos)\n",
    "    print(\"zero to one: \", zeros / ones)\n",
    "\n",
    "# Calculate the ratio for the training data\n",
    "calculate_class_ratio(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441496 2359\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "max_len = 0\n",
    "min_len = float('inf')\n",
    "for key, value in all_data.items():\n",
    "    if value['gt'].shape[0] > max_len:\n",
    "        max_len = value['gt'].shape[0]\n",
    "    if value['gt'].shape[0] < min_len:\n",
    "        min_len = value['gt'].shape[0]\n",
    "print(max_len, min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0873, 0.1211],\n",
       "         [0.4919, 0.9066],\n",
       "         [0.8772, 0.7136]]),\n",
       " tensor([[ 8.7325e-02,  1.2112e-01],\n",
       "         [ 4.9191e-01,  9.0664e-01],\n",
       "         [-9.9000e+01,  7.1360e-01]]),\n",
       " False,\n",
       " False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,2)\n",
    "b = a.clone()\n",
    "b[2,0] = -99\n",
    "a, b, a.requires_grad, b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 5, 6],\n",
       "        [1, 4, 6]]),\n",
       " array([[6, 1, 4],\n",
       "        [4, 2, 6],\n",
       "        [0, 1, 6]]),\n",
       " array([[38, 19, 78],\n",
       "        [22, 15, 64]]),\n",
       " (2, 3))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.randint(0,7, (2,3))\n",
    "b = np.random.randint(0,7, (3,3))\n",
    "a,b,np.dot(a,b),np.dot(a,b).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
