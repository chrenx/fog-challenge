{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/disk4/chrenx/fog-challenge\n"
     ]
    }
   ],
   "source": [
    "import joblib, math, os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.constants import physical_constants, degree\n",
    "from tqdm import tqdm\n",
    "os.chdir('/local/disk4/chrenx/fog-challenge')\n",
    "print(os.getcwd())\n",
    "\n",
    "def sample_normalize(sample):\n",
    "    \"\"\"Mean-std normalization function. \n",
    "\n",
    "    Args:\n",
    "        sample: (N,)\n",
    "    Returns:\n",
    "        normalized_sample: (N,)\n",
    "    \"\"\"\n",
    "    if not isinstance(sample, torch.Tensor):\n",
    "        sample = torch.tensor(sample)\n",
    "    mean = torch.mean(sample)\n",
    "    std = torch.std(sample)\n",
    "    # Normalize the sample and handle division by zero\n",
    "    eps = 1e-8\n",
    "    normalized_sample = (sample - mean) / (std + eps)\n",
    "    return normalized_sample  # (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wer', 'wer', 'wer'], dtype='<U3')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(['wer'] * 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_daphnet.p: 17, 35\n",
      "all_kaggle_pd_data_defog.p: 91, 1027\n",
      "all_kaggle_pd_data_tdcsfog.p: 833, 833\n",
      "all_turn_in_place.p: 71, 71\n"
     ]
    }
   ],
   "source": [
    "dpath = ['data/rectified_data/all_data/all_daphnet.p', \n",
    "         'data/rectified_data/all_data/all_kaggle_pd_data_defog.p',\n",
    "         'data/rectified_data/all_data/all_kaggle_pd_data_tdcsfog.p',\n",
    "         'data/rectified_data/all_data/all_turn_in_place.p']\n",
    "for p in dpath:\n",
    "    data = joblib.load(p)\n",
    "    unique_ori_filename = set()\n",
    "    for key,value in data.items():\n",
    "        unique_ori_filename.add(value['ori_filename'])\n",
    "    print(f\"{p.split('/')[-1]}: {len(unique_ori_filename)}, {len(data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'S02R01.txt', 'S03R02.txt'}\n"
     ]
    }
   ],
   "source": [
    "daphnet_all_dpath = 'data/rectified_data/all_data/all_daphnet.p'\n",
    "daphnet_test_dpath = 'data/rectified_data/all_data/test_daphnet_window1024_randomaug.p' \n",
    "all_data = joblib.load(daphnet_all_dpath)\n",
    "test_data = joblib.load(daphnet_test_dpath)\n",
    "\n",
    "test_ori_filename = set()\n",
    "\n",
    "for key, value in test_data.items():\n",
    "    test_ori_filename.add(value['ori_filename'])\n",
    "print(len(test_ori_filename), test_ori_filename)\n",
    "\n",
    "\n",
    "def dict_to_csv(dictionary, csv_filename):\n",
    "    # Convert each tensor in the dictionary to a list\n",
    "    converted_dict = {key: value.tolist() for key, value in dictionary.items()}\n",
    "    \n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(converted_dict)\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "for key, value in all_data.items():\n",
    "    if value['ori_filename'] not in test_ori_filename:\n",
    "        continue\n",
    "    input_dict = {\n",
    "        'L_Ankle_Acc_X': value['L_Ankle_Acc_AP'],\n",
    "        'L_Ankle_Acc_Y': value['L_Ankle_Acc_V'],\n",
    "        'L_Ankle_Acc_Z': value['L_Ankle_Acc_ML'],\n",
    "        'L_MidLatThigh_Acc_X': value['L_MidLatThigh_Acc_AP'],\n",
    "        'L_MidLatThigh_Acc_Y': value['L_MidLatThigh_Acc_V'],\n",
    "        'L_MidLatThigh_Acc_Z': value['L_MidLatThigh_Acc_ML'],\n",
    "        'LowerBack_Acc_X': value['LowerBack_Acc_AP'],\n",
    "        'LowerBack_Acc_Y': value['LowerBack_Acc_V'],\n",
    "        'LowerBack_Acc_Z': value['LowerBack_Acc_ML'],\n",
    "    }\n",
    "    csv_filename = f'data/submission_test_data/{key}.csv'\n",
    "    dict_to_csv(input_dict, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daphnet_all_dpath = 'data/rectified_data/all_data/all_daphnet.p'\n",
    "daphnet_test_dpath = 'data/rectified_data/all_data/test_daphnet_window1024_randomaug.p' \n",
    "all_data = joblib.load(daphnet_all_dpath)\n",
    "test_data = joblib.load(daphnet_test_dpath)\n",
    "\n",
    "test_ori_filename = set()\n",
    "\n",
    "for key, value in test_data.items():\n",
    "    test_ori_filename.add(value['ori_filename'])\n",
    "print(len(test_ori_filename), test_ori_filename)\n",
    "\n",
    "\n",
    "def dict_to_csv(dictionary, csv_filename):\n",
    "    # Convert each tensor in the dictionary to a list\n",
    "    converted_dict = {key: value.tolist() for key, value in dictionary.items()}\n",
    "    \n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(converted_dict)\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "for key, value in all_data.items():\n",
    "    if value['ori_filename'] not in test_ori_filename:\n",
    "        continue\n",
    "    input_dict = {\n",
    "        'L_Ankle_Acc_X': value['L_Ankle_Acc_AP'],\n",
    "        'L_Ankle_Acc_Y': value['L_Ankle_Acc_V'],\n",
    "        'L_Ankle_Acc_Z': value['L_Ankle_Acc_ML'],\n",
    "        'L_MidLatThigh_Acc_X': value['L_MidLatThigh_Acc_AP'],\n",
    "        'L_MidLatThigh_Acc_Y': value['L_MidLatThigh_Acc_V'],\n",
    "        'L_MidLatThigh_Acc_Z': value['L_MidLatThigh_Acc_ML'],\n",
    "        'LowerBack_Acc_X': value['LowerBack_Acc_AP'],\n",
    "        'LowerBack_Acc_Y': value['LowerBack_Acc_V'],\n",
    "        'LowerBack_Acc_Z': value['LowerBack_Acc_ML'],\n",
    "    }\n",
    "    csv_filename = f'data/submission_test_data/{key}.csv'\n",
    "    dict_to_csv(input_dict, csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:05<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dpath = 'data/dataset_fog_release/dataset'\n",
    "\n",
    "all_txt_files = os.listdir(dpath)\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "physical_const = physical_constants['standard acceleration of gravity'][0]\n",
    "\n",
    "\n",
    "count = 0\n",
    "for txt_file in tqdm(all_txt_files, total=len(all_txt_files)):\n",
    "    file = open(os.path.join(dpath, txt_file))\n",
    "    \n",
    "    all_lines = file.readlines()\n",
    "    \n",
    "    ankle_acc_ap, ankle_acc_v, ankle_acc_ml = [], [], []\n",
    "    mid_thigh_acc_ap, mid_thigh_acc_v, mid_thigh_acc_ml = [], [], []\n",
    "    lowerback_acc_ap, lowerback_acc_v, lowerback_acc_ml = [], [], []\n",
    "    gt = []\n",
    "    \n",
    "    # print(txt_file)\n",
    "    # print(all_lines[0])\n",
    "    # break\n",
    "    \n",
    "    for line in all_lines:\n",
    "        line = line.strip().split(' ')\n",
    "        if int(line[-1]) == 0 and len(ankle_acc_ap) < 700:\n",
    "            ankle_acc_ap, ankle_acc_v, ankle_acc_ml = [], [], []\n",
    "            mid_thigh_acc_ap, mid_thigh_acc_v, mid_thigh_acc_ml = [], [], []\n",
    "            lowerback_acc_ap, lowerback_acc_v, lowerback_acc_ml = [], [], []\n",
    "            gt = []\n",
    "            continue\n",
    "        elif int(line[-1]) == 0 and len(ankle_acc_ap) >= 700:\n",
    "            count += 1\n",
    "            event = ['stand or walk or turn'] * len(ankle_acc_ap)\n",
    "            all_data[f'rectified_{count}_daphnet'] = {\n",
    "                'ori_filename':txt_file,\n",
    "                'event': np.array(event), \n",
    "                'L_Ankle_Acc_AP': sample_normalize(torch.tensor(ankle_acc_ap, dtype=torch.float32)),\n",
    "                'L_Ankle_Acc_V': sample_normalize(torch.tensor(ankle_acc_v, dtype=torch.float32)),\n",
    "                'L_Ankle_Acc_ML': sample_normalize(torch.tensor(ankle_acc_ml, dtype=torch.float32)),\n",
    "                'L_MidLatThigh_Acc_AP': sample_normalize(torch.tensor(mid_thigh_acc_ap, dtype=torch.float32)),\n",
    "                'L_MidLatThigh_Acc_V': sample_normalize(torch.tensor(mid_thigh_acc_v, dtype=torch.float32)),\n",
    "                'L_MidLatThigh_Acc_ML': sample_normalize(torch.tensor(mid_thigh_acc_ml, dtype=torch.float32)),\n",
    "                'LowerBack_Acc_AP': sample_normalize(torch.tensor(lowerback_acc_ap, dtype=torch.float32)),\n",
    "                'LowerBack_Acc_V': sample_normalize(torch.tensor(lowerback_acc_v, dtype=torch.float32)),\n",
    "                'LowerBack_Acc_ML': sample_normalize(torch.tensor(lowerback_acc_ml, dtype=torch.float32)),\n",
    "                'gt': torch.tensor(gt, dtype=torch.float32),\n",
    "            }\n",
    "            ankle_acc_ap, ankle_acc_v, ankle_acc_ml = [], [], []\n",
    "            mid_thigh_acc_ap, mid_thigh_acc_v, mid_thigh_acc_ml = [], [], []\n",
    "            lowerback_acc_ap, lowerback_acc_v, lowerback_acc_ml = [], [], []\n",
    "            gt = []\n",
    "        else:\n",
    "            ankle_acc_ap.append(float(line[1]) * physical_const / 1000)\n",
    "            ankle_acc_v.append(float(line[2]) * physical_const / 1000)\n",
    "            ankle_acc_ml.append(float(line[3]) * physical_const / 1000)\n",
    "            mid_thigh_acc_ap.append(float(line[4]) * physical_const / 1000)\n",
    "            mid_thigh_acc_v.append(float(line[5]) * physical_const / 1000)\n",
    "            mid_thigh_acc_ml.append(float(line[6]) * physical_const / 1000)\n",
    "            lowerback_acc_ap.append(float(line[7]) * physical_const / 1000)\n",
    "            lowerback_acc_v.append(float(line[8]) * physical_const / 1000)\n",
    "            lowerback_acc_ml.append(float(line[9]) * physical_const / 1000)\n",
    "            gt.append(int(line[10]))    \n",
    "    \n",
    "    if len(ankle_acc_ap) >= 700:\n",
    "        count += 1\n",
    "        event = ['stand or walk or turn'] * len(ankle_acc_ap)\n",
    "        all_data[f'rectified_{count}_daphnet'] = {\n",
    "            'ori_filename':txt_file,\n",
    "            'event': np.array(event), \n",
    "            'L_Ankle_Acc_AP': sample_normalize(torch.tensor(ankle_acc_ap, dtype=torch.float32)),\n",
    "            'L_Ankle_Acc_V': sample_normalize(torch.tensor(ankle_acc_v, dtype=torch.float32)),\n",
    "            'L_Ankle_Acc_ML': sample_normalize(torch.tensor(ankle_acc_ml, dtype=torch.float32)),\n",
    "            'L_MidLatThigh_Acc_AP': sample_normalize(torch.tensor(mid_thigh_acc_ap, dtype=torch.float32)),\n",
    "            'L_MidLatThigh_Acc_V': sample_normalize(torch.tensor(mid_thigh_acc_v, dtype=torch.float32)),\n",
    "            'L_MidLatThigh_Acc_ML': sample_normalize(torch.tensor(mid_thigh_acc_ml, dtype=torch.float32)),\n",
    "            'LowerBack_Acc_AP': sample_normalize(torch.tensor(lowerback_acc_ap, dtype=torch.float32)),\n",
    "            'LowerBack_Acc_V': sample_normalize(torch.tensor(lowerback_acc_v, dtype=torch.float32)),\n",
    "            'LowerBack_Acc_ML': sample_normalize(torch.tensor(lowerback_acc_ml, dtype=torch.float32)),\n",
    "            'gt': torch.tensor(gt, dtype=torch.float32),\n",
    "        }\n",
    "    file.close()\n",
    "\n",
    "joblib.dump(all_data, open(os.path.join('data/rectified_data/all_data', \n",
    "                                                f\"all_daphnet.p\"), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle_pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833/833 [24:44<00:00,  1.78s/it] \n"
     ]
    }
   ],
   "source": [
    "lab_home = 'tdcsfog'\n",
    "dpath = f'data/kaggle_pd_data/train/{lab_home}'\n",
    "all_tdcsfog = [file for file in os.listdir(dpath) if file.endswith('csv')]\n",
    "\n",
    "all_data = {}\n",
    "count = 0\n",
    "physical_const = physical_constants['standard acceleration of gravity'][0]\n",
    "\n",
    "for csv_file in tqdm(all_tdcsfog, total=len(all_tdcsfog)):\n",
    "    count += 1\n",
    "\n",
    "    df = pd.read_csv(os.path.join(dpath, csv_file))\n",
    "    df['gt'] = df.apply(lambda row: 1 if row[['StartHesitation', 'Turn', 'Walking']].any() \\\n",
    "                                            else 0, axis=1)\n",
    "    df['event'] = df.apply(lambda row: 'start hesitation' if row['StartHesitation'] == 1 else\n",
    "                                        'turn' if row['Turn'] == 1 else\n",
    "                                        'walk' if row['Walking'] == 1 else\n",
    "                                        'unlabeled', axis=1)\n",
    "\n",
    "    all_data[f'rectified_{count}_kaggle_pd_data'] = {\n",
    "        'ori_filename': f\"{lab_home}_\" + csv_file,\n",
    "        'event': df['event'].to_numpy(), \n",
    "        'LowerBack_Acc_V': sample_normalize(torch.tensor(df['AccV'].to_numpy(), \n",
    "                                                         dtype=torch.float32)),\n",
    "        'LowerBack_Acc_ML': sample_normalize(torch.tensor(df['AccML'].to_numpy(), \n",
    "                                                          dtype=torch.float32)),\n",
    "        'LowerBack_Acc_AP': sample_normalize(torch.tensor(df['AccAP'].to_numpy(), \n",
    "                                                          dtype=torch.float32)),\n",
    "        'gt': torch.tensor(df['gt'].to_numpy(), dtype=torch.float32),\n",
    "    }\n",
    "        \n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data'].keys())\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['ori_filename'])\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['event'].shape)\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['LowerBack_Acc_V'].shape)\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['LowerBack_Acc_V'].dtype)\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['gt'].shape)\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['gt'].dtype)\n",
    "joblib.dump(all_data, open(os.path.join('data/rectified_data/all_data', \n",
    "                                        f\"all_kaggle_pd_data_{lab_home}.p\"), 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2818/2818 [13:18<00:00,  3.53it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num trials:  1027\n"
     ]
    }
   ],
   "source": [
    "TASK = {\n",
    "    '4MW': '4-meter walk',\n",
    "    'TUG-ST': 'stand up, walk, return and sit down',\n",
    "    'TUG-DT': 'stand up, walk, return and sit down while subtracting numbers',\n",
    "    'Turning-ST': 'performing 360-degree turns 4 times, each time alternating the rotation direction',\n",
    "    'Turning-DT': 'performing 360-degree turns 4 times, each time alternating the rotation direction, and subtracting numbers at the same time',\n",
    "    'Hotspot1': 'a walking trial that involves opening a door, entering another room, turning, and returning to the start point',\n",
    "    'Hotspot2': 'walking through an area in the house',\n",
    "    'MB1': 'sit to stand', \n",
    "    'MB2a': 'rise to toes',\n",
    "    'MB2b': 'rise to toes',\n",
    "    'MB3-L': 'stand on the left leg',\n",
    "    'MB3-R': 'stand on the right leg',\n",
    "    'MB4': 'compensatory stepping correction - forward',\n",
    "    'MB5': 'compensatory stepping correction - backward',\n",
    "    'MB6-L': 'compensatory stepping correction - left lateral',\n",
    "    'MB6-R': 'compensatory stepping correction - right lateral',\n",
    "    'MB7': 'stand in the posture: feet together, eyes open, and firm surface',\n",
    "    'MB8': 'stand in the posture: feet together, eyes closed, and foam surface',\n",
    "    'MB9': 'incline eyes closed (shoulder width, arms at your side)',\n",
    "    'MB10': 'change in gait speed',\n",
    "    'MB11': 'walk with head turns - horizontal',\n",
    "    'MB12': 'walk with pivot turns',\n",
    "    'MB13': 'step over obstacles',\n",
    "}\n",
    "\n",
    "lab_home = 'defog'\n",
    "dpath = f'data/kaggle_pd_data/train/{lab_home}'\n",
    "all_tdcsfog = [file for file in os.listdir(dpath) if file.endswith('csv')]\n",
    "\n",
    "all_data = {}\n",
    "count = 0\n",
    "physical_const = physical_constants['standard acceleration of gravity'][0]\n",
    "\n",
    "tasks_txt_file = open('data/kaggle_pd_data/tasks.csv')\n",
    "all_lines = tasks_txt_file.readlines()\n",
    "\n",
    "count = 0\n",
    "for line in tqdm(all_lines, total=len(all_lines)):\n",
    "    line = line.strip().split(',')\n",
    "    if line[-1] not in TASK.keys():\n",
    "        continue\n",
    "    csv_file = line[0] + '.csv'\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(dpath, csv_file))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    start_t = int(math.floor(float(line[1]) * 100))\n",
    "    end_t = int(math.ceil(float(line[2]) * 100))\n",
    "\n",
    "    while not df['Valid'].iloc[start_t] or not df['Task'].iloc[start_t]:\n",
    "        start_t += 1\n",
    "        \n",
    "    while not df['Valid'].iloc[end_t] or not df['Task'].iloc[end_t]:\n",
    "        end_t -= 1\n",
    "        \n",
    "    if (end_t - start_t + 1) < 900:\n",
    "        continue\n",
    "\n",
    "    df = df.iloc[start_t:end_t+1]\n",
    "    \n",
    "    df['gt'] = df.apply(lambda row: 1 if row[['StartHesitation', 'Turn', 'Walking']].any() \\\n",
    "                                            else 0, axis=1)\n",
    "\n",
    "    event = [TASK[line[-1]]] * (end_t - start_t + 1) \n",
    "    event = np.array(event)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    \n",
    "    # print(df['AccV'].iloc[:3])\n",
    "\n",
    "    all_data[f'rectified_{count}_kaggle_pd_data'] = {\n",
    "        'ori_filename': f\"{lab_home}_\" + csv_file,\n",
    "        'event': event, \n",
    "        'LowerBack_Acc_V': sample_normalize(torch.tensor(df['AccV'].to_numpy(), \n",
    "                                                         dtype=torch.float32) * physical_const),\n",
    "        'LowerBack_Acc_ML': sample_normalize(torch.tensor(df['AccML'].to_numpy(), \n",
    "                                                          dtype=torch.float32) * physical_const),\n",
    "        'LowerBack_Acc_AP': sample_normalize(torch.tensor(df['AccAP'].to_numpy(), \n",
    "                                                          dtype=torch.float32) * physical_const),\n",
    "        'gt': torch.tensor(df['gt'].to_numpy(), dtype=torch.float32),\n",
    "    }\n",
    "    \n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data'].keys())\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['ori_filename'])\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['event'].shape)\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['LowerBack_Acc_V'][:3])\n",
    "    # break\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['gt'].shape)\n",
    "    # print(all_data[f'rectified_{count}_kaggle_pd_data']['gt'].dtype)\n",
    "joblib.dump(all_data, open(os.path.join('data/rectified_data/all_data', \n",
    "                                        f\"all_kaggle_pd_data_{lab_home}.p\"), 'wb'))\n",
    "print('num trials: ', len(all_data.keys()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# turn_in_place_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/71 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:05<00:00, 13.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdfeinfo = pd.read_csv('data/turn_in_place/pdfeinfo.csv')\n",
    "dpath = 'data/turn_in_place/IMU'\n",
    "all_txt_files = [file for file in os.listdir(dpath) \\\n",
    "                if file.endswith('txt') and not file.endswith('standing.txt')]\n",
    "\n",
    "all_data = {}\n",
    "count = 0\n",
    "physical_const = physical_constants['standard acceleration of gravity'][0]\n",
    "for txt_file in tqdm(all_txt_files, total=len(all_txt_files)):\n",
    "    count += 1\n",
    "    subject_id = txt_file[3:5]\n",
    "    session_num = txt_file[6]\n",
    "    row = pdfeinfo[pdfeinfo['id'] == f'pdfe{subject_id}']\n",
    "    l_or_r = 'L' if row.iloc[0]['more_affected_side'] == 'left' else 'R'\n",
    "\n",
    "    if l_or_r == 'R':\n",
    "        continue\n",
    "\n",
    "    tug_time = row.iloc[0][f's{session_num}_tug_sec']\n",
    "    tug_dual_time = row.iloc[0][f's{session_num}_tug_dual_sec']\n",
    "\n",
    "    frame_idx = []\n",
    "    event = []\n",
    "    acc_ml, acc_ap, acc_si = [], [], []\n",
    "    gyr_ml, gyr_ap, gyr_si = [], [], []\n",
    "    gt = []\n",
    "    \n",
    "    with open(os.path.join(dpath, txt_file), 'r') as file:\n",
    "        all_lines = file.readlines()\n",
    "        \n",
    "        for line in all_lines[1:]:\n",
    "            values = line.strip().split('\\t')\n",
    "            annotation = 'turn in place' if float(values[1]) >= tug_time else 'unlabeled'\n",
    "            annotation = 'turn in place with additional tasks' \\\n",
    "                                if float(values[1]) >= tug_dual_time else annotation\n",
    "\n",
    "            frame_idx.append(int(values[0]))\n",
    "            event.append(annotation)\n",
    "            # g --> m/s^2\n",
    "            acc_ml.append(float(values[2]) * physical_const)\n",
    "            acc_ap.append(float(values[3]) * physical_const)\n",
    "            acc_si.append(float(values[4]) * physical_const)\n",
    "            gyr_ml.append(float(values[5]) * degree)\n",
    "            gyr_ap.append(float(values[6]) * degree)\n",
    "            gyr_si.append(float(values[7]) * degree)\n",
    "            \n",
    "            gt.append(int(values[8]))\n",
    "            \n",
    "            # print(acc_x[-1], acc_z[-1], acc_y[-1])\n",
    "            # print(gyr_x[-1], gyr_z[-1], gyr_y[-1])\n",
    "            # break\n",
    "        \n",
    "        # print(torch.tensor(acc_x)[:3])\n",
    "        all_data[f'rectified_{count}_turn_in_place_l'] = {\n",
    "            'ori_filename':txt_file,\n",
    "            'frame_idx': torch.tensor(frame_idx), \n",
    "            'event': np.array(event), \n",
    "            f'{l_or_r}_LatShank_Acc_ML': sample_normalize(torch.tensor(acc_ml, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Acc_AP': sample_normalize(torch.tensor(acc_ap, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Acc_SI': sample_normalize(torch.tensor(acc_si, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Gyr_ML': sample_normalize(torch.tensor(gyr_ml, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Gyr_AP': sample_normalize(torch.tensor(gyr_ap, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Gyr_SI': sample_normalize(torch.tensor(gyr_si, dtype=torch.float32)),\n",
    "            'gt': torch.tensor(gt, dtype=torch.float32),\n",
    "        }\n",
    "        \n",
    "        # print(all_data[f'rectified_{count}_turn_in_place'].keys())\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place']['ori_filename'])\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place']['event'].shape)\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place'][f'{l_or_r}_LatShank_Acc_X'].shape)\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place'][f'{l_or_r}_LatShank_Acc_X'].dtype)\n",
    "    joblib.dump(all_data, open(os.path.join('data/rectified_data/all_data', \n",
    "                                                f\"all_turn_in_place_l.p\"), 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# turn_in_place_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:05<00:00, 13.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdfeinfo = pd.read_csv('data/turn_in_place/pdfeinfo.csv')\n",
    "dpath = 'data/turn_in_place/IMU'\n",
    "all_txt_files = [file for file in os.listdir(dpath) \\\n",
    "                if file.endswith('txt') and not file.endswith('standing.txt')]\n",
    "\n",
    "all_data = {}\n",
    "count = 0\n",
    "physical_const = physical_constants['standard acceleration of gravity'][0]\n",
    "for txt_file in tqdm(all_txt_files, total=len(all_txt_files)):\n",
    "    count += 1\n",
    "    subject_id = txt_file[3:5]\n",
    "    session_num = txt_file[6]\n",
    "    row = pdfeinfo[pdfeinfo['id'] == f'pdfe{subject_id}']\n",
    "    l_or_r = 'L' if row.iloc[0]['more_affected_side'] == 'left' else 'R'\n",
    "\n",
    "    if l_or_r == 'L':\n",
    "        continue\n",
    "\n",
    "    tug_time = row.iloc[0][f's{session_num}_tug_sec']\n",
    "    tug_dual_time = row.iloc[0][f's{session_num}_tug_dual_sec']\n",
    "\n",
    "    frame_idx = []\n",
    "    event = []\n",
    "    acc_ml, acc_ap, acc_si = [], [], []\n",
    "    gyr_ml, gyr_ap, gyr_si = [], [], []\n",
    "    gt = []\n",
    "    \n",
    "    with open(os.path.join(dpath, txt_file), 'r') as file:\n",
    "        all_lines = file.readlines()\n",
    "        \n",
    "        for line in all_lines[1:]:\n",
    "            values = line.strip().split('\\t')\n",
    "            annotation = 'turn in place' if float(values[1]) >= tug_time else 'unlabeled'\n",
    "            annotation = 'turn in place with additional tasks' \\\n",
    "                                if float(values[1]) >= tug_dual_time else annotation\n",
    "\n",
    "            frame_idx.append(int(values[0]))\n",
    "            event.append(annotation)\n",
    "            # g --> m/s^2\n",
    "            acc_ml.append(float(values[2]) * physical_const)\n",
    "            acc_ap.append(float(values[3]) * physical_const)\n",
    "            acc_si.append(float(values[4]) * physical_const)\n",
    "            gyr_ml.append(float(values[5]) * degree)\n",
    "            gyr_ap.append(float(values[6]) * degree)\n",
    "            gyr_si.append(float(values[7]) * degree)\n",
    "            \n",
    "            gt.append(int(values[8]))\n",
    "            \n",
    "            # print(acc_x[-1], acc_z[-1], acc_y[-1])\n",
    "            # print(gyr_x[-1], gyr_z[-1], gyr_y[-1])\n",
    "            # break\n",
    "        \n",
    "        # print(torch.tensor(acc_x)[:3])\n",
    "        all_data[f'rectified_{count}_turn_in_place_r'] = {\n",
    "            'ori_filename':txt_file,\n",
    "            'frame_idx': torch.tensor(frame_idx), \n",
    "            'event': np.array(event), \n",
    "            f'{l_or_r}_LatShank_Acc_ML': sample_normalize(torch.tensor(acc_ml, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Acc_AP': sample_normalize(torch.tensor(acc_ap, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Acc_SI': sample_normalize(torch.tensor(acc_si, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Gyr_ML': sample_normalize(torch.tensor(gyr_ml, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Gyr_AP': sample_normalize(torch.tensor(gyr_ap, dtype=torch.float32)),\n",
    "            f'{l_or_r}_LatShank_Gyr_SI': sample_normalize(torch.tensor(gyr_si, dtype=torch.float32)),\n",
    "            'gt': torch.tensor(gt, dtype=torch.float32),\n",
    "        }\n",
    "        \n",
    "        # print(all_data[f'rectified_{count}_turn_in_place'].keys())\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place']['ori_filename'])\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place']['event'].shape)\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place'][f'{l_or_r}_LatShank_Acc_X'].shape)\n",
    "        # print(all_data[f'rectified_{count}_turn_in_place'][f'{l_or_r}_LatShank_Acc_X'].dtype)\n",
    "    joblib.dump(all_data, open(os.path.join('data/rectified_data/all_data', \n",
    "                                                f\"all_turn_in_place_r.p\"), 'wb'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
