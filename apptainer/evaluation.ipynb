{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/disk4/chrenx/fog-challenge\n"
     ]
    }
   ],
   "source": [
    "import os, joblib, torch\n",
    "os.chdir('/local/disk4/chrenx/fog-challenge')\n",
    "print(os.getcwd())\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(output, gt):\n",
    "    \"\"\"Generate precision, recall, and f1 score.\n",
    "\n",
    "    Args:\n",
    "        output: (B, window, 1)   # prob class\n",
    "        gt (inference):   (B, window, 3)   # one hot\n",
    "    \"\"\"\n",
    "    # Convert the model output probabilities to class predictions\n",
    "    pred = torch.round(output)  # (B, window, 1)\n",
    "\n",
    "    # Extract the first two classes from the ground truth\n",
    "    real = torch.argmax(gt[:, :, :2], dim=-1, keepdim=True)  # (B, window, 1)\n",
    "\n",
    "    # Create a mask to ignore the positions where the ground truth class is 2\n",
    "    mask = (gt[:, :, 2] != 1).unsqueeze(-1)  # (B, window, 1)\n",
    "\n",
    "    # Apply the mask to the predictions and ground truth\n",
    "    pred = (pred * mask.float()).squeeze() # (B, window)\n",
    "    real = (real * mask.float()).squeeze() # (B, window)\n",
    "    \n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = ((pred == 1) & (real == 1)).float().sum()\n",
    "    fp = ((pred == 1) & (real == 0)).float().sum()\n",
    "    fn = ((pred == 0) & (real == 1)).float().sum()\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    \n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]),\n",
       " dict_keys(['series_name', 'ori_series_name', 'start_t_idx', 'end_t_idx', 'model_input', 'gt', 'inference_gt']))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dpath = 'data/rectified_data/kaggle_pd_data/test_kaggle_pd_data_window6976_lab_randomaug.p'\n",
    "test_data = joblib.load(test_dpath)\n",
    "test_data.keys(), test_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "for idx, element in test_data.items():\n",
    "    dpath = os.path.join('data/rectified_data/kaggle_pd_data/tdcsfog', element['ori_series_name'][:-8]+'.csv')\n",
    "    shutil.copy2(dpath, 'submission/unet_1/test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25, 6976, 3]), torch.Size([25, 6976, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = torch.stack([test_data[i]['model_input'] for i in range(len(test_data.keys()))])\n",
    "gt = torch.stack([test_data[i]['gt'] for i in range(len(test_data.keys()))])\n",
    "model_input = model_input.to(device)\n",
    "gt = gt.to(device)\n",
    "model_input.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<All keys matched successfully>,\n",
       " UNet(\n",
       "   (relu): ReLU()\n",
       "   (sigmoid): Sigmoid()\n",
       "   (e11): Conv1d(3, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (e12): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (maxpool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (e21): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (e22): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (maxpool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (e31): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (e32): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (maxpool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (e41): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (e42): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (maxpool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (e51): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (e52): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (maxpool5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (d51): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (d52): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (up5): ConvTranspose1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "   (d41): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (d42): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (up4): ConvTranspose1d(256, 512, kernel_size=(2,), stride=(2,))\n",
       "   (d31): Conv1d(768, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (d32): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (up3): ConvTranspose1d(128, 512, kernel_size=(2,), stride=(2,))\n",
       "   (d21): Conv1d(640, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (d22): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (up2): ConvTranspose1d(64, 512, kernel_size=(2,), stride=(2,))\n",
       "   (d11): Conv1d(576, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (d12): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "   (up1): ConvTranspose1d(64, 512, kernel_size=(2,), stride=(2,))\n",
       "   (outconv): Conv1d(544, 1, kernel_size=(3,), stride=(1,), padding=same)\n",
       " ))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from submission.unet_1.codes.unet_v3 import UNet\n",
    "weights_path = \"submission/unet_1/weights/best_model_f1_3150.pt\"\n",
    "model = UNet(3)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(weights_path)['model']), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count num of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5784897"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_model_parameters(model): \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) \n",
    "\n",
    "count_model_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8476548790931702,\n",
       " tensor(0.8808, device='cuda:0'),\n",
       " tensor(0.8639, device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.permute(model_input, (0,2,1)) # (B, num_feats, window)\n",
    "    test_pred = model(test_input) # (B, 1, window)\n",
    "    test_pred = torch.permute(test_pred, (0, 2, 1)) # (B, window, 1)\n",
    "    prec, recall, f1 = evaluation_metrics(test_pred, gt)\n",
    "prec.item(), recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoG Model Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 6976])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.permute(model_input, (0,2,1)) # (B, num_feats, window)\n",
    "    test_pred = model(test_input) # (B, 1, window)\n",
    "    output = torch.permute(test_pred, (0, 2, 1)) # (25, window, 1)\n",
    "    \n",
    "\n",
    "pred = torch.round(output)  # (B, window, 1)\n",
    "\n",
    "# Extract the first two classes from the ground truth\n",
    "real = torch.argmax(gt[:, :, :2], dim=-1, keepdim=True)  # (B, window, 1)\n",
    "\n",
    "# Create a mask to ignore the positions where the ground truth class is 2\n",
    "mask = (gt[:, :, 2] != 1).unsqueeze(-1)  # (B, window, 1)\n",
    "\n",
    "# Apply the mask to the predictions and ground truth\n",
    "output = (pred * mask.float()).squeeze() # (B, window)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "sample: 808, length: 6976\n",
      "sample: 60, length: 6976\n",
      "sample: 703, length: 13952\n",
      "sample: 289, length: 13952\n",
      "sample: 698, length: 13952\n",
      "sample: 127, length: 6976\n",
      "sample: 721, length: 6976\n",
      "sample: 354, length: 6976\n",
      "sample: 654, length: 6976\n",
      "sample: 285, length: 6976\n",
      "sample: 443, length: 6976\n",
      "sample: 738, length: 48832\n",
      "sample: 122, length: 6976\n",
      "sample: 481, length: 6976\n",
      "sample: 696, length: 6976\n",
      "sample: 223, length: 6976\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "grouped_data = {}\n",
    "for i in range(output.shape[0]):\n",
    "    sample = test_data[i]\n",
    "    ori_series_name = sample['ori_series_name']\n",
    "    \n",
    "    a = output[i].cpu().numpy()\n",
    "    a[a == 0.0] = 0\n",
    "    a[a == 1.0] = 1\n",
    "    a[a == 2.0] = 2\n",
    "    \n",
    "    if ori_series_name not in grouped_data:\n",
    "        grouped_data[ori_series_name] = a\n",
    "    else:\n",
    "        \n",
    "        grouped_data[ori_series_name] = np.concatenate((grouped_data[ori_series_name], \n",
    "                                                        a))\n",
    "print(len(grouped_data.keys()))\n",
    "for key, value in grouped_data.items():\n",
    "    print(f\"sample: {key.split('_')[1]}, length: {value.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame to hold the merged data\n",
    "data = {f\"ModelOutput_Trial{key.split('_')[1]}\": value.astype(int).tolist() for key, value in grouped_data.items()}\n",
    "\n",
    "max_len = max(len(v) for v in data.values())\n",
    "\n",
    "for key in data:\n",
    "    data[key] += [None] * (max_len - len(data[key]))\n",
    "    \n",
    "for key in data:\n",
    "    for i in range(len(data[key])):\n",
    "        if data[key][i] is not None:\n",
    "            data[key][i] = int(data[key][i])\n",
    "\n",
    "\n",
    "# with open('submission/RenHaocheng_FoG_Ground_Truth_Data.csv', 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     # Write the header\n",
    "#     writer.writerow(data.keys())\n",
    "#     # Write the rows\n",
    "#     writer.writerows(zip(*data.values()))\n",
    "    \n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('submission/RenHaocheng_FoG_Model_Output_Data.csv', index=False)\n",
    "df = pd.read_csv('submission/RenHaocheng_FoG_Model_Output_Data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoG GT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "sample: 808, length: 6976\n",
      "sample: 60, length: 6976\n",
      "sample: 703, length: 13952\n",
      "sample: 289, length: 13952\n",
      "sample: 698, length: 13952\n",
      "sample: 127, length: 6976\n",
      "sample: 721, length: 6976\n",
      "sample: 354, length: 6976\n",
      "sample: 654, length: 6976\n",
      "sample: 285, length: 6976\n",
      "sample: 443, length: 6976\n",
      "sample: 738, length: 48832\n",
      "sample: 122, length: 6976\n",
      "sample: 481, length: 6976\n",
      "sample: 696, length: 6976\n",
      "sample: 223, length: 6976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert one-hot encoding to a single value\n",
    "def one_hot_to_label(one_hot):\n",
    "    a = torch.argmax(one_hot[:, :], dim=-1)\n",
    "    a[a == 2] = 0\n",
    "    return a\n",
    "\n",
    "# Group samples by 'ori_series_name'\n",
    "grouped_data = {}\n",
    "\n",
    "for i in range(len(test_data.keys())):\n",
    "    sample = test_data[i]\n",
    "    ori_series_name = sample['ori_series_name']\n",
    "    gt_label = one_hot_to_label(sample['gt'])\n",
    "    \n",
    "    if ori_series_name not in grouped_data:\n",
    "        grouped_data[ori_series_name] = gt_label.cpu().numpy()\n",
    "    else:\n",
    "        grouped_data[ori_series_name] = np.concatenate((grouped_data[ori_series_name], \n",
    "                                                        gt_label.cpu().numpy()))\n",
    "\n",
    "print(len(grouped_data.keys()))\n",
    "for key, value in grouped_data.items():\n",
    "    print(f\"sample: {key.split('_')[1]}, length: {value.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Create a DataFrame to hold the merged data\n",
    "data = {f\"GroundTruth_Trial{key.split('_')[1]}\": value.astype(int).tolist() for key, value in grouped_data.items()}\n",
    "\n",
    "max_len = max(len(v) for v in data.values())\n",
    "\n",
    "for key in data:\n",
    "    data[key] += [None] * (max_len - len(data[key]))\n",
    "\n",
    "# with open('submission/RenHaocheng_FoG_Ground_Truth_Data.csv', 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     # Write the header\n",
    "#     writer.writerow(data.keys())\n",
    "#     # Write the rows\n",
    "#     writer.writerows(zip(*data.values()))\n",
    "    \n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('submission/RenHaocheng_FoG_Ground_Truth_Data.csv', index=False)\n",
    "    \n",
    "# with open('submission/RenHaocheng_FoG_Ground_Truth_Data.csv', 'w', newline='') as csvfile:\n",
    "#     for key, value in data.items():\n",
    "#         df = pd.DataFrame({key: value})\n",
    "#         df.to_csv(csvfile, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
